{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leser inn bibliotek og genererer testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leser inn bibliotek og setter opp spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dapla as dp\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../ssb_sparktools/processing/processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myspark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lager testdata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarkiske data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarki_schema = StructType([\n",
    "                              StructField('persid', StringType(), False),\n",
    "                              StructField('dato', StringType(), False),\n",
    "                              StructField('arbeidsgiver',ArrayType(\n",
    "                                                                      StructType([StructField('navn',StringType(),True),\n",
    "                                                                                  StructField('adresse',StringType(),True),\n",
    "                                                                                  StructField('ansatte', ArrayType(\n",
    "                                                                                      StructType([StructField('navn', StringType(), True),\n",
    "                                                                                                  StructField('adresse',StringType(),True)])))\n",
    "                                                                                 ])\n",
    "                                                                     )),\n",
    "                              StructField('utdanning',ArrayType(\n",
    "                                                                      StructType([StructField('utdanningsinstitusjon',StringType(),True),\n",
    "                                                                                  StructField('adresse',StringType(),True),\n",
    "                                                                                  StructField('utdanning', ArrayType(\n",
    "                                                                                      StructType([StructField('fag', StringType(), True),\n",
    "                                                                                                  StructField('eksamensdato',StringType(),True)])))\n",
    "                                                                                 ])\n",
    "                                                                     ))\n",
    "                             ])\n",
    "hierarkidata_raw = [('#ID1', '01Jan2020', [('Industri AS', 'Jernveien 24', [('Per', 'Storgata 3'),('Kari', 'Toppen 2')])], [('Mek Skole', 'Mek veien 1',[('Mekaniskefag', '21Jun2013'), ('Byggingeniør', '11Jun2018')])]),\n",
    "                    ('#ID2', '02Mar2020', [('Lommerusk AS', 'Sliteveien 23', [('Espen', 'Ukjent'),('Ronny', 'Kaiegata 2')])], [('Harde Skole', 'Kjeppveien 10', [('Grunnskole', '19Jun2014')])]),\n",
    "                    ('#ID3', '15Feb2020', [('Papir AS', 'Papirveien 24', [('Ole', 'Storgata 3'),('Siri', 'Toppen 3')])], [('Skogen Skole', 'Treveien 5', [('Papirfag', '21Jun2014'), ('Papiringeniør', '11Jun2012')])])]\n",
    "hierarki_testdata = myspark.createDataFrame(hierarkidata_raw, hierarki_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skriver ut testdata som er laget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarki_testdata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarki_testdata.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test av funksjonen *cross_sectional*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uten spark_session som parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dato_hendelsedata = hierarki_testdata.withColumn('dato', F.to_timestamp('dato', \"ddMMMyyyy\"))\n",
    "tverrsnitt = cross_sectional(dato_hendelsedata, 'dato', ['persid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tverrsnitt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Med spark_session som parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dato_hendelsedata = hierarki_testdata.withColumn('dato', F.to_timestamp('dato', \"ddMMMyyyy\"))\n",
    "tverrsnitt = cross_sectional(dato_hendelsedata, 'dato', ['persid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tverrsnitt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tar tverrsnitt på en gitt dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFDATO = '2020-03-01 00:00:00'\n",
    "referansedato = datetime.strptime(REFDATO, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tverrsnitt_co = cross_sectional(dato_hendelsedata, 'dato', ['persid'], coDate=referansedato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tverrsnitt_co.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test av funksjonen *unpack_parquet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uten spark_session som parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakketut = unpack_parquet(hierarki_testdata)\n",
    "for k in pakketut.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Med spark_session som parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakketut = unpack_parquet(hierarki_testdata, spark_session=myspark)\n",
    "for k in pakketut.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viser utpakket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakketut['arbeidsgiver'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakketut['arbeidsgiver_ansatte'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakketut['utdanning'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakketut['utdanning_utdanning-child'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Totalt antall dataframes: {len(pakketut)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict_less = unpack_parquet(hierarki_testdata, levels=1, spark_session=myspark)\n",
    "print(f'Totalt antall dataframes: {len(test_dict_less)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (k8s cluster)",
   "language": "python",
   "name": "pyspark_k8s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
